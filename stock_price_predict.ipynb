{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Rz3KV83MRUZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('./Top_performer_NL.xlsx')\n",
        "df.columns = df.iloc[0]\n",
        "df = df[1:]\n",
        "df.head()"
      ],
      "metadata": {
        "id": "mNLtII5zMgHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_string_to_float(s):\n",
        "    try:\n",
        "        # Remove any commas from the string\n",
        "        s = str(s)  # Convert to string if it's not already\n",
        "        s = s.replace(\",\", \"\")\n",
        "        # Convert the string to a float\n",
        "        return float(s)\n",
        "    except ValueError:\n",
        "        return None\n",
        "\n",
        "# Apply the function to the entire column\n",
        "df['%'] = df['%'].apply(convert_string_to_float)\n",
        "df['Last'] = df['Last'].apply(convert_string_to_float)\n",
        "df['Turnover'] = df['Turnover'].apply(convert_string_to_float)\n",
        "df['Volume'] = df['Volume'].apply(convert_string_to_float)"
      ],
      "metadata": {
        "id": "Xi61hkr-MhyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "plt.plot(df['Last'])\n",
        "plt.title('Market Close price.', fontsize=15)\n",
        "plt.ylabel('Price in euro.')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LY5l4pGQMjTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check whether data in the ‘Close’ column and that available in the ‘Adj Close’ column is the same with each row or not\n",
        "#df[df['Close'] == df['Adj Close']].shape\n",
        "#df = df.drop(['Adj Close'], axis=1)\n",
        "\n",
        "# check for null values\n",
        "df.isnull().sum()\n",
        "\n",
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "pfLUo0diMkn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualise features\n",
        "features = ['Turnover', 'Last', 'Volume', '%']\n",
        "\n",
        "plt.subplots(figsize=(20,10))\n",
        "\n",
        "for i, col in enumerate(features):\n",
        "  plt.subplot(2,3,i+1)\n",
        "  sb.distplot(df[col])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k2t0C-B6Mo5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from these boxplots we can see if there are any outliers\n",
        "plt.subplots(figsize=(20,10))\n",
        "for i, col in enumerate(features):\n",
        "  plt.subplot(2,3,i+1)\n",
        "  sb.boxplot(df[col])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2KK4fDW_MqOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feature Engineering\n",
        "# quarterly results affect the stock prices heavily\n",
        "# splitted = df['Date'].str.split('/', expand=True)\n",
        "\n",
        "# df['day'] = splitted[1].astype('int')\n",
        "# df['month'] = splitted[0].astype('int')\n",
        "# df['year'] = splitted[2].astype('int')\n",
        "\n",
        "# df['is_quarter_end'] = np.where(df['month']%3==0,1,0)\n",
        "\n",
        "# df['open-close'] = df['Open'] - df['Close']\n",
        "# df['low-high'] = df['Low'] - df['High']\n",
        "# target feature is a signal whether to buy or not\n",
        "df['target'] = np.where(df['Last'].shift(-1) > df['Last'], 1, 0)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "MLmeM4HoMrhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_grouped = df.groupby('year').mean()\n",
        "# plt.subplots(figsize=(20,10))\n",
        "\n",
        "# for i, col in enumerate(['Last', 'Volume', '%', 'Turnover']):\n",
        "#   plt.subplot(2,2,i+1)\n",
        "#   data_grouped[col].plot.bar()\n",
        "# plt.show()\n",
        "\n",
        "# Check whether Prices are higher in the months which are quarter end as compared to that of the non-quarter end months.\n",
        "# Check the volume of trades in the months which are quarter end.\n",
        "#df.groupby('is_quarter_end').mean()\n",
        "\n",
        "plt.pie(df['target'].value_counts().values,\n",
        "\t\tlabels=[0, 1], autopct='%1.1f%%')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "utrA7303MtHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_feat = df[['%', 'Volume','Turnover','Last']]\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "# As our concern is with the highly correlated features only so, we will visualize our heatmap as per that criteria only.\n",
        "sb.heatmap(df_feat.corr() > 0.9, annot=True, cbar=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "edQOewi7MxTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data splitting and Normalization\n",
        "features = df[['Volume', 'Turnover', '%']]\n",
        "target = df['target']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "features = scaler.fit_transform(features)\n",
        "\n",
        "X_train, X_valid, Y_train, Y_valid = train_test_split(\n",
        "\tfeatures, target, test_size=0.1, random_state=2022)\n",
        "print(X_train.shape, X_valid.shape)"
      ],
      "metadata": {
        "id": "_yjaPIOiMy20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model development and Evaluation\n",
        "#  instead of predicting the hard probability that is 0 or 1 we would like it to predict soft probabilities that are continuous values between 0 to 1.\n",
        "# And with soft probabilities, the ROC-AUC curve is generally used\n",
        "models = [LogisticRegression(), SVC(\n",
        "kernel='poly', probability=True), XGBClassifier()]\n",
        "\n",
        "for i in range(3):\n",
        "  models[i].fit(X_train, Y_train)\n",
        "\n",
        "print(f'{models[i]} : ')\n",
        "print('Training Accuracy : ', metrics.roc_auc_score(\n",
        "\tY_train, models[i].predict_proba(X_train)[:,1]))\n",
        "print('Validation Accuracy : ', metrics.roc_auc_score(\n",
        "\tY_valid, models[i].predict_proba(X_valid)[:,1]))\n",
        "print()"
      ],
      "metadata": {
        "id": "inh4BynEMz_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ConfusionMatrixDisplay.from_estimator(models[0], X_valid, Y_valid)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Vg-lz7t3M1gp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}